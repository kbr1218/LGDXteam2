{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Router Chain Test\n",
    "#### *LLM 체인 라우팅 적용하기*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 00. 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('API_KEY_GEMINI')\n",
    "OPENAI_API_KEY = os.getenv('API_KEY_OPENAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "lgdx_team2_routerchain\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"lgdx_team2_routerchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from operator import itemgetter\n",
    "\n",
    "# 랭체인 환경 설정\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# VectorDB - FAISS\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 01. 벡터DB 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspaces\\LGDXteam2\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 임베딩 모델 생성\n",
    "# https://huggingface.co/ibm-granite/granite-embedding-278m-multilingual\n",
    "embeddings = HuggingFaceEmbeddings(model_name='ibm-granite/granite-embedding-278m-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 로드\n",
    "new_vector_store = FAISS.load_local(\"../movies_vectorstore_faiss_1500\",\n",
    "                                    embeddings=embeddings,\n",
    "                                    allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 02. Router Chain: 사용자 질문 유형 구분\n",
    "\n",
    "- 정보검색\n",
    "- 추천요청\n",
    "- 일반대화 (`default_chain`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructuredOutputParser 사용\n",
    "response_schemas = [\n",
    "  ResponseSchema(name=\"type\",\n",
    "                 description=\"사용자의 입력을 세 가지 범주('정보검색', '추천요청', '일반대화') 중 하나로 구분\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 출력 지시사항 파싱\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 입력값 유형 분류용 프롬프트\n",
    "classification_template = \"\"\"사용자의 입력을 다음 세 가지 범주 중 하나로 분류하세요:\n",
    "1️⃣ **\"정보검색\"**: 특정 영화, 드라마, 배우, 감독, 러닝타임, 개봉 연도, 수상 내역, 필모그래피 등 **사실적인 정보를 찾는 질문**\n",
    "   - 기대되는 응답 예시: 배우가 출연한 드라마/영화 목록, 특정 연도의 개봉작 리스트 등\n",
    "2️⃣ **\"추천요청\"**: 특정 장르, 배우, 테마(예: 좀비, 시간여행), 감성(예: 힐링, 긴장감) 등에 대한 **추천을 요청하는 질문**\n",
    "   - 기대되는 응답 예시: 특정 조건을 만족하는 영화/드라마 추천\n",
    "3️⃣ **\"일반대화\"**: 서비스와 무관한 일반적인 대화 (예: 날씨, AI 관련 질문, 잡담)\n",
    "\n",
    "#### **예시 형식**\n",
    "{format_instructions}\n",
    "\n",
    "<user_input>\n",
    "{user_input}\n",
    "</user_input>\n",
    "\"\"\"\n",
    "classification_prompt = ChatPromptTemplate.from_template(classification_template,\n",
    "                                                         partial_variables={'format_instructions': format_instructions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LLM을 이용한 질문 유형 분류 체인\n",
    "classification_chain = (\n",
    "  classification_prompt\n",
    "  | ChatGoogleGenerativeAI(model='gemini-1.5-flash', api_key=GEMINI_API_KEY)\n",
    "  | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': '추천요청'}\n",
      "{'type': '추천요청'}\n",
      "{'type': '일반대화'}\n"
     ]
    }
   ],
   "source": [
    "# 질문 분류 테스트\n",
    "print(classification_chain.invoke({'user_input': \"2023년에 개봉한 액션 영화 뭐 있어?\"}))\n",
    "\n",
    "# 추천 요청 예상 질문\n",
    "print(classification_chain.invoke({'user_input': '디카프리오가 주연한 영화 추천해줘.'}))\n",
    "\n",
    "# 일반 대화 예상 질문\n",
    "print(classification_chain.invoke({'user_input': \"너가 제일 좋아하는 영화 뭐야?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리 자료형을 string으로 변환하는 함수\n",
    "def format_change(classification_result: dict, user_input: str) -> str:\n",
    "    type_value = classification_result.get(\"classification_result\", {}).get(\"type\", \"일반대화\")\n",
    "    # keywords = classification_result.get(\"classification_result\", {}).get(\"keywords\", [])\n",
    "\n",
    "    # string 자료형으로 변경\n",
    "    # formatted_str = f\"type: '{type_value}', keywords: {keywords}, user_input: '{user_input}'\"\n",
    "    formatted_str = f\"type: '{type_value}', user_input: '{user_input}'\"\n",
    "    return formatted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 03. Destination Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *1. default-chain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> model loaded...\n"
     ]
    }
   ],
   "source": [
    "# default_chain 생성 (사용자의 의미없는 입력값에 대해 정해진 답변을 할 때)\n",
    "# 프롬프트 템플릿 설정\n",
    "default_template = \"\"\"\n",
    "\"You are a chatbot that must always respond with '🐶: 멍멍!'.\n",
    "No matter what question the user asks, always reply with '🐶: 멍멍!'\"\n",
    "\n",
    "[사용자 입력]:\n",
    "{user_input}\n",
    "[분류 결과]:\n",
    "{classification_result}\n",
    "\"\"\"\n",
    "default_prompt = ChatPromptTemplate.from_template(default_template)\n",
    "\n",
    "# Google Gemini 모델 생성\n",
    "def load_gemini():\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "        model='gemini-1.5-flash',\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        api_key=GEMINI_API_KEY\n",
    "    )\n",
    "    print(\">>>>>>> model loaded...\")\n",
    "    return model\n",
    "\n",
    "default_llm = load_gemini()\n",
    "\n",
    "# langchain 체인 구성\n",
    "default_chain = (\n",
    "  {\"classification_result\": RunnablePassthrough(),\n",
    "   \"user_input\": RunnablePassthrough()}\n",
    "  | default_prompt\n",
    "  | default_llm\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2. search-chain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr>\n",
    "\n",
    "#### *3. recommendation-chain*\n",
    "- 추천 목록을 반환하는 체인\n",
    "- `next_input`이 필요 없음 + 정해진 자료형으로 답해야 함  \n",
    "  => `RouterOutputParser`를 사용해보는 게 좋을 거 같음..~\n",
    "- 이 체인 뒤에 사용자 시청 기록 기반으로 반환된 추천 목록에서 5개를 정하는 작업을 해야 함\n",
    "\n",
    "<br>\n",
    "\n",
    "- 장르 기반 추천 ⇒ 장르\n",
    "- 줄거리(키워드/컨셉) 기반 추천 ⇒ 줄거리\n",
    "- 특정 연도 및 시대별 콘텐츠 추천 ⇒ 줄거리에 언급되는 시대배경/연도\n",
    "==================================================\n",
    "- 콘텐츠 정보 기반 추천 ⇒ 어떤 행이 있는지 봐야할듯\n",
    "- 인기 있는 콘텐츠 추천 ⇒ 시청횟수가 많은 것\n",
    "- 리뷰(감성) 기반 추천 ⇒ 리뷰\n",
    "- 사용자 선호 기반 추천 ⇒ 사용자 시청기록\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructuredOutputParser 사용\n",
    "recommend_response_schemas = [\n",
    "  ResponseSchema(name=\"candidates\",\n",
    "                 description=\"사용자의 입력에 맞게 추천할 VOD 콘텐츠의 인덱스 리스트. 예: [1, 10, 31, 89, 135, 180]\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(recommend_response_schemas)\n",
    "\n",
    "# 출력 지시사항 파싱\n",
    "recommend_chain_format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 생성\n",
    "recommend_chain_retriever = new_vector_store.as_retriever(\n",
    "    search_type=\"mmr\",   \n",
    "    search_kwargs={\"k\": 20,              # 반환할 문서 수 (default: 4)\n",
    "                   \"fetch_k\": 50,       # MMR 알고리즘에 전달할 문서 수\n",
    "                   \"lambda_mult\": 0.8,  # 결과 다양성 조절 (default: 0.5),\n",
    "                   }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 설정\n",
    "recommend_chain_template = \"\"\"\n",
    "You are a movie-recommendation chatbot.\n",
    "You must only answer based on the given context.\n",
    "Do not generate answers that are not directly supported by the context.\n",
    "사용자의 요청에 따라 추천할 VOD 콘텐츠의 **인덱스 리스트**를 반환하세요.\n",
    "\n",
    "**중요**:\n",
    "- 추천 리스트에는 반드시 **[Context]**에서 제공된 문서만 포함해야 합니다.\n",
    "- **[Context]**에 없는 문서를 절대 생성하거나 포함하지 마세요.\n",
    "- **[Context]**에 적절한 추천이 없을 경우, 빈 리스트를 반환하세요.\n",
    "\n",
    "응답은 JSON 형식으로 **오직 추천된 콘텐츠의 인덱스 리스트**만 포함해야 합니다.\n",
    "{recommend_chain_format_instructions}\n",
    "---\n",
    "예제 출력 형식:\n",
    "```json\n",
    "{{\"candidates\": [1, 10, 31, 89, 135, 180]}}```\n",
    "(만약 적절한 추천이 없을 경우)\n",
    "```json\n",
    "{{\"candidates\": []}}```\n",
    "\n",
    "[사용자 입력과 사용자 입력값의 유형]:\n",
    "{formatted_string}\n",
    "\n",
    "[Context]:\n",
    "{recommend_chain_retriever}\n",
    "\n",
    "[Answer]:\n",
    "\"\"\"\n",
    "recommend_chain_prompt = ChatPromptTemplate.from_template(recommend_chain_template,\n",
    "                                                          partial_variables={'recommend_chain_format_instructions': recommend_chain_format_instructions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> Gemini loaded...\n"
     ]
    }
   ],
   "source": [
    "# LLM 모델 생성 (1. GEMINI 2. OpenAI)\n",
    "def load_gemini(system_instruction):\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "        model='gemini-1.5-flash',\n",
    "        temperature=0.3,\n",
    "        max_tokens=5000,\n",
    "        system_instruction=system_instruction,\n",
    "        api_key=GEMINI_API_KEY\n",
    "    )\n",
    "    print(\">>>>>>> Gemini loaded...\")\n",
    "    return model\n",
    "\n",
    "def load_gpt(system_instruction):\n",
    "    model = ChatOpenAI(\n",
    "        model_name='gpt-4o-mini-2024-07-18',\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    print(\">>>>>>> GPT loaded...\")\n",
    "    return model\n",
    "\n",
    "system_instruction = \"\"\"you are a movie-recommendation chatbot. you must answer based on given data.\"\"\"\n",
    "recommend_chain_llm = load_gemini(system_instruction)\n",
    "\n",
    "# langchain 체인 구성\n",
    "recommend_chain = (\n",
    "  {\"formatted_string\":RunnablePassthrough(),\n",
    "    \"recommend_chain_retriever\": recommend_chain_retriever,\n",
    "  }\n",
    "  | recommend_chain_prompt               # 하나로 만든 문서를 prompt에 넘겨주고\n",
    "  | recommend_chain_llm                  # llm이 원하는 답변을 만듦\n",
    "  | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "## 04. Full Chain 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(classification_result: dict, user_input: str):\n",
    "    # 사용자의 입력 유형 분류\n",
    "    print(user_input)\n",
    "    type_value = classification_result.get(\"type\", \"일반대화\")  # 기본값 설정\n",
    "    # keywords = classification_data.get(\"keywords\", [])  # 기본값 설정\n",
    "    \n",
    "    print(f\"===================== Type: {type_value}\")\n",
    "    # print(f\"===================== Keywords: {keywords}\")\n",
    "    \n",
    "    if type_value == '정보검색':\n",
    "        return \"정보검색 체인 실행은 여기!!!\"\n",
    "    elif type_value == '추천요청':\n",
    "        formatted_string = format_change(classification_result, user_input)\n",
    "        candidates = recommend_chain.invoke(formatted_string)\n",
    "        return candidates\n",
    "    else:\n",
    "        return default_chain.invoke({\"classification_result\": classification_result, \"user_input\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "  {\"classification_result\": classification_chain,\n",
    "   \"user_input\":itemgetter(\"user_input\")}\n",
    "  | RunnableLambda(lambda x: process_user_input(x[\"classification_result\"], x[\"user_input\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "액션영화 추천해줘\n",
      "===================== Type: 추천요청\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidates': [5620, 3309]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"user_input\": \"액션영화 추천해줘\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr>\n",
    "\n",
    "### *데이터 확인*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../../data/영화_TMDB_5800_Mapping-최종-addIndex.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>orgnl_cntry</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>genre</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1789</td>\n",
       "      <td>돈키호테를 죽인 사나이</td>\n",
       "      <td>스페인</td>\n",
       "      <td>297725</td>\n",
       "      <td>보드카 광고 촬영을 위해 스페인의 작은 마을로 오게 된 잘 나가는 천재 CF 감독 ...</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>False</td>\n",
       "      <td>/xr9ZchDO4CwFdJMNoB3I924NuCd.jpg</td>\n",
       "      <td>en</td>\n",
       "      <td>The Man Who Killed Don Quixote</td>\n",
       "      <td>/sjr9cVpq8H7qcmLps8X0Cjn1sxB.jpg</td>\n",
       "      <td>11.271</td>\n",
       "      <td>132</td>\n",
       "      <td>6.766</td>\n",
       "      <td>1006</td>\n",
       "      <td>모험, 코미디</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index          name orgnl_cntry  movie_id  \\\n",
       "1788   1789  돈키호테를 죽인 사나이         스페인    297725   \n",
       "\n",
       "                                               overview release_date  adult  \\\n",
       "1788  보드카 광고 촬영을 위해 스페인의 작은 마을로 오게 된 잘 나가는 천재 CF 감독 ...   2018-05-19  False   \n",
       "\n",
       "                         backdrop_path original_language  \\\n",
       "1788  /xr9ZchDO4CwFdJMNoB3I924NuCd.jpg                en   \n",
       "\n",
       "                      original_title                       poster_path  \\\n",
       "1788  The Man Who Killed Don Quixote  /sjr9cVpq8H7qcmLps8X0Cjn1sxB.jpg   \n",
       "\n",
       "      popularity  runtime  vote_average  vote_count    genre  test  \n",
       "1788      11.271      132         6.766        1006  모험, 코미디     1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies['index']==1789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
